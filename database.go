// æ•°æ®åº“ç®¡ç†æ¨¡å— - è´Ÿè´£PostgreSQLæ•°æ®åº“çš„è¿æ¥ã€æ“ä½œå’Œä¼˜åŒ–
// åŠŸèƒ½ï¼šæ–‡ä»¶è®°å½•çš„å¢åˆ æ”¹æŸ¥ã€æ‰¹é‡æ“ä½œã€è¿æ¥æ± ç®¡ç†ã€æ€§èƒ½ä¼˜åŒ–
// ç‰¹æ€§ï¼šæ”¯æŒæ‰¹é‡æ’å…¥ã€è¿æ¥æ± ä¼˜åŒ–ã€äº‹åŠ¡å¤„ç†ã€ç»Ÿè®¡æŸ¥è¯¢
package main

import (
	"database/sql"
	"fmt"
	"sync"
	"time"

	_ "github.com/lib/pq" // PostgreSQLé©±åŠ¨
)

// FileInfo æ–‡ä»¶ä¿¡æ¯æ•°æ®ç»“æ„ä½“
// ç”¨äºå­˜å‚¨æ–‡ä»¶çš„å®Œæ•´å…ƒæ•°æ®ä¿¡æ¯ï¼ŒåŒ…æ‹¬å“ˆå¸Œå€¼ã€è·¯å¾„ã€å¤§å°ç­‰
type FileInfo struct {
	ID           int64     `db:"id"`            // æ•°æ®åº“è‡ªå¢ä¸»é”®
	Hash         string    `db:"hash"`          // æ–‡ä»¶å“ˆå¸Œå€¼(ç”¨äºé‡å¤æ£€æµ‹ï¼Œå»ºç«‹å”¯ä¸€ç´¢å¼•)
	OriginalName string    `db:"original_name"` // åŸå§‹æ–‡ä»¶å
	OriginalPath string    `db:"original_path"` // åŸå§‹æ–‡ä»¶å®Œæ•´è·¯å¾„
	NewPath      string    `db:"new_path"`      // ç§»åŠ¨åçš„æ–°æ–‡ä»¶è·¯å¾„
	FileName     string    `db:"file_name"`     // æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
	FileSize     int64     `db:"file_size"`     // æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
	Extension    string    `db:"extension"`     // æ–‡ä»¶æ‰©å±•åï¼ˆå°å†™ï¼‰
	CreatedAt    time.Time `db:"created_at"`    // æ–‡ä»¶åˆ›å»ºæ—¶é—´
	ProcessedAt  time.Time `db:"processed_at"`  // ç³»ç»Ÿå¤„ç†æ—¶é—´
	SourcePath   string    `db:"source_path"`   // æºæ–‡ä»¶è·¯å¾„
	TargetPath   string    `db:"target_path"`   // ç›®æ ‡æ–‡ä»¶è·¯å¾„
	HashType     string    `db:"hash_type"`     // å“ˆå¸Œç®—æ³•ç±»å‹ï¼ˆmd5/sha256ï¼‰
}

// Database æ•°æ®åº“è¿æ¥ç®¡ç†å™¨
// æä¾›é«˜æ€§èƒ½çš„æ•°æ®åº“æ“ä½œï¼Œæ”¯æŒæ‰¹é‡å¤„ç†å’Œè¿æ¥æ± ä¼˜åŒ–
type Database struct {
	db          *sql.DB       // æ•°æ®åº“è¿æ¥å¯¹è±¡
	batchBuffer []FileInfo    // æ‰¹é‡æ’å…¥ç¼“å†²åŒºï¼Œæé«˜æ’å…¥æ€§èƒ½
	batchMutex  sync.Mutex    // æ‰¹é‡æ“ä½œäº’æ–¥é”ï¼Œä¿è¯çº¿ç¨‹å®‰å…¨
	batchSize   int           // æ‰¹é‡å¤„ç†å¤§å°ï¼Œé»˜è®¤1000æ¡
	batchTimer  *time.Timer   // æ‰¹é‡å®šæ—¶å™¨ï¼Œå®šæœŸåˆ·æ–°ç¼“å†²åŒº
}

// InitDatabase åˆå§‹åŒ–æ•°æ®åº“è¿æ¥å’Œé…ç½®
// å‚æ•°ï¼šconfig - æ•°æ®åº“é…ç½®ä¿¡æ¯
// è¿”å›ï¼šæ•°æ®åº“ç®¡ç†å™¨å®ä¾‹å’Œé”™è¯¯ä¿¡æ¯
// åŠŸèƒ½ï¼šå»ºç«‹è¿æ¥ã€é…ç½®è¿æ¥æ± ã€åˆ›å»ºè¡¨ç»“æ„ã€å¯åŠ¨æ‰¹é‡å¤„ç†å®šæ—¶å™¨
func InitDatabase(config DatabaseConfig) (*Database, error) {
	LogInfo("ğŸ”— æ­£åœ¨åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
	LogDebug("ğŸ“‹ æ•°æ®åº“é…ç½®: host=%s, port=%d, database=%s, sslmode=%s", 
		config.Host, config.Port, config.Database, config.SSLMode)
	
	// æ„å»ºPostgreSQLè¿æ¥å­—ç¬¦ä¸²
	dsn := fmt.Sprintf("host=%s port=%d user=%s password=%s dbname=%s sslmode=%s",
		config.Host, config.Port, config.Username, config.Password, config.Database, config.SSLMode)

	// å»ºç«‹æ•°æ®åº“è¿æ¥
	db, err := sql.Open("postgres", dsn)
	if err != nil {
		LogError("âŒ è¿æ¥æ•°æ®åº“å¤±è´¥: %v", err)
		return nil, fmt.Errorf("è¿æ¥æ•°æ®åº“å¤±è´¥: %v", err)
	}

	// æµ‹è¯•æ•°æ®åº“è¿æ¥å¯ç”¨æ€§
	LogDebug("ğŸ” æ­£åœ¨æµ‹è¯•æ•°æ®åº“è¿æ¥...")
	if err := db.Ping(); err != nil {
		db.Close()
		LogError("âŒ æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥: %v", err)
		return nil, fmt.Errorf("æ•°æ®åº“è¿æ¥æµ‹è¯•å¤±è´¥: %v", err)
	}

	// ä¼˜åŒ–è¿æ¥æ± å‚æ•° - æ ¹æ®æ€§èƒ½éœ€æ±‚è°ƒæ•´
	LogDebug("âš™ï¸ é…ç½®æ•°æ®åº“è¿æ¥æ± å‚æ•°...")
	db.SetMaxOpenConns(50)        // å¢åŠ æœ€å¤§è¿æ¥æ•°ä»¥æ”¯æŒæ›´é«˜å¹¶å‘
	db.SetMaxIdleConns(10)        // å¢åŠ ç©ºé—²è¿æ¥æ•°
	db.SetConnMaxLifetime(10 * time.Minute) // å»¶é•¿è¿æ¥ç”Ÿå‘½å‘¨æœŸ
	db.SetConnMaxIdleTime(5 * time.Minute)  // è®¾ç½®ç©ºé—²è¿æ¥è¶…æ—¶

	// åˆ›å»ºæ•°æ®åº“ç®¡ç†å™¨å®ä¾‹
	database := &Database{
		db:          db,
		batchBuffer: make([]FileInfo, 0, 100), // åˆå§‹åŒ–æ‰¹é‡ç¼“å†²åŒºï¼Œé¢„åˆ†é…100ä¸ªå…ƒç´ å®¹é‡
		batchSize:   50,                       // æ‰¹é‡å¤§å°è®¾ä¸º50ï¼Œå¹³è¡¡æ€§èƒ½å’Œå†…å­˜ä½¿ç”¨
	}

	// åˆ›å»ºæ•°æ®è¡¨å’Œç´¢å¼•
	LogDebug("ğŸ“Š æ­£åœ¨åˆ›å»º/éªŒè¯æ•°æ®è¡¨...")
	if err := database.createTables(); err != nil {
		db.Close()
		LogError("âŒ åˆ›å»ºæ•°æ®è¡¨å¤±è´¥: %v", err)
		return nil, fmt.Errorf("åˆ›å»ºæ•°æ®è¡¨å¤±è´¥: %v", err)
	}

	// å¯åŠ¨æ‰¹é‡å¤„ç†å®šæ—¶å™¨ï¼Œå®šæœŸåˆ·æ–°ç¼“å†²åŒº
	LogDebug("â° å¯åŠ¨æ‰¹é‡å¤„ç†å®šæ—¶å™¨...")
	database.startBatchTimer()

	LogInfo("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼Œè¿æ¥æ± é…ç½®: MaxOpen=%d, MaxIdle=%d", 50, 10)
	return database, nil
}

// createTables åˆ›å»ºå¿…è¦çš„æ•°æ®è¡¨å’Œç´¢å¼•
// åŠŸèƒ½ï¼šåˆ›å»ºfile_recordsè¡¨ï¼Œå»ºç«‹æ€§èƒ½ä¼˜åŒ–ç´¢å¼•
// ç‰¹æ€§ï¼šæ”¯æŒå“ˆå¸Œå”¯ä¸€æ€§çº¦æŸã€æ‰©å±•åç´¢å¼•ã€æ—¶é—´ç´¢å¼•
func (d *Database) createTables() error {
	LogDebug("ğŸ—ï¸ å¼€å§‹åˆ›å»ºæ•°æ®è¡¨å’Œç´¢å¼•...")
	
	// åˆ›å»ºæ–‡ä»¶è®°å½•è¡¨çš„SQLè¯­å¥
	// åŒ…å«å®Œæ•´çš„æ–‡ä»¶å…ƒæ•°æ®å­—æ®µå’Œæ€§èƒ½ä¼˜åŒ–ç´¢å¼•
	createTableSQL := `
	CREATE TABLE IF NOT EXISTS file_records (
		id SERIAL PRIMARY KEY,                                    -- è‡ªå¢ä¸»é”®
		hash VARCHAR(128) UNIQUE NOT NULL,                        -- æ–‡ä»¶å“ˆå¸Œå€¼ï¼Œå”¯ä¸€çº¦æŸ
		original_name VARCHAR(500) NOT NULL,                      -- åŸå§‹æ–‡ä»¶å
		file_size BIGINT NOT NULL,                               -- æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
		extension VARCHAR(50) NOT NULL,                          -- æ–‡ä»¶æ‰©å±•å
		created_at TIMESTAMP NOT NULL,                           -- æ–‡ä»¶åˆ›å»ºæ—¶é—´
		processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,        -- ç³»ç»Ÿå¤„ç†æ—¶é—´
		source_path TEXT NOT NULL,                               -- æºæ–‡ä»¶è·¯å¾„
		target_path TEXT,                                        -- ç›®æ ‡æ–‡ä»¶è·¯å¾„
		hash_type VARCHAR(20) NOT NULL DEFAULT 'sha256'          -- å“ˆå¸Œç®—æ³•ç±»å‹
	);

	-- åˆ›å»ºæ€§èƒ½ä¼˜åŒ–ç´¢å¼•ï¼Œæé«˜æŸ¥è¯¢æ•ˆç‡
	CREATE UNIQUE INDEX IF NOT EXISTS idx_file_records_hash_unique ON file_records(hash);           -- å“ˆå¸Œå€¼å”¯ä¸€ç´¢å¼•
	CREATE INDEX IF NOT EXISTS idx_file_records_extension ON file_records(extension);               -- æ‰©å±•åç´¢å¼•
	CREATE INDEX IF NOT EXISTS idx_file_records_processed_at ON file_records(processed_at DESC);    -- å¤„ç†æ—¶é—´å€’åºç´¢å¼•
	CREATE INDEX IF NOT EXISTS idx_file_records_file_size ON file_records(file_size DESC);
	CREATE INDEX IF NOT EXISTS idx_file_records_hash_type ON file_records(hash_type);
	
	-- å¤åˆç´¢å¼•ä¼˜åŒ–å¸¸è§æŸ¥è¯¢
	CREATE INDEX IF NOT EXISTS idx_file_records_ext_size ON file_records(extension, file_size DESC);
	CREATE INDEX IF NOT EXISTS idx_file_records_ext_processed ON file_records(extension, processed_at DESC);
	
	-- éƒ¨åˆ†ç´¢å¼•ä¼˜åŒ–å¤§æ–‡ä»¶æŸ¥è¯¢
	CREATE INDEX IF NOT EXISTS idx_file_records_large_files ON file_records(file_size DESC) 
		WHERE file_size > 1048576; -- å¤§äº1MBçš„æ–‡ä»¶
	`

	_, err := d.db.Exec(createTableSQL)
	if err != nil {
		LogError("âŒ æ‰§è¡Œåˆ›å»ºè¡¨SQLå¤±è´¥: %v", err)
		return fmt.Errorf("æ‰§è¡Œåˆ›å»ºè¡¨SQLå¤±è´¥: %v", err)
	}

	LogInfo("âœ… æ•°æ®è¡¨åˆ›å»º/éªŒè¯å®Œæˆï¼Œç´¢å¼•ä¼˜åŒ–å®Œæˆ")
	return nil
}

// FileExistsWithDetails æ£€æŸ¥æ–‡ä»¶å“ˆå¸Œæ˜¯å¦å·²å­˜åœ¨ï¼Œè¿”å›è¯¦ç»†ä¿¡æ¯
func (db *Database) FileExistsWithDetails(hash string) (bool, *FileInfo, error) {
	startTime := time.Now()
	defer func() {
		duration := time.Since(startTime)
		if duration > 100*time.Millisecond {
			LogWarn("âš ï¸ æ•°æ®åº“æŸ¥è¯¢è€—æ—¶è¾ƒé•¿ (FileExistsWithDetails): %v", duration)
		} else {
			LogDebug("â±ï¸ æ•°æ®åº“æŸ¥è¯¢è€—æ—¶ (FileExistsWithDetails): %v", duration)
		}
	}()

	var fileInfo FileInfo
	query := `SELECT id, hash, original_name, original_path, new_path, file_name, 
			  file_size, extension, created_at, processed_at, source_path, 
			  target_path, hash_type FROM file_records WHERE hash = $1 LIMIT 1`
	
	err := db.db.QueryRow(query, hash).Scan(
		&fileInfo.ID, &fileInfo.Hash, &fileInfo.OriginalName, &fileInfo.OriginalPath,
		&fileInfo.NewPath, &fileInfo.FileName, &fileInfo.FileSize, &fileInfo.Extension,
		&fileInfo.CreatedAt, &fileInfo.ProcessedAt, &fileInfo.SourcePath,
		&fileInfo.TargetPath, &fileInfo.HashType,
	)
	
	if err != nil {
		if err == sql.ErrNoRows {
			LogDebug("ğŸ” æ–‡ä»¶å“ˆå¸Œä¸å­˜åœ¨: %s", hash[:12]+"...")
			return false, nil, nil
		}
		LogError("âŒ æŸ¥è¯¢æ–‡ä»¶è®°å½•å¤±è´¥: %v", err)
		return false, nil, fmt.Errorf("æŸ¥è¯¢æ–‡ä»¶è®°å½•å¤±è´¥: %v", err)
	}
	
	LogDebug("âœ… å‘ç°é‡å¤æ–‡ä»¶: %s -> %s", hash[:12]+"...", fileInfo.TargetPath)
	return true, &fileInfo, nil
}

// FileExists æ£€æŸ¥æ–‡ä»¶å“ˆå¸Œæ˜¯å¦å·²å­˜åœ¨ï¼Œä¼˜å…ˆè¿”å›target_pathï¼Œå¦‚æœä¸ºç©ºåˆ™è¿”å›original_path
func (db *Database) FileExists(hash string) (bool, string, error) {
	exists, fileInfo, err := db.FileExistsWithDetails(hash)
	if err != nil {
		return false, "", err
	}
	
	if !exists {
		return false, "", nil
	}
	
	// ä¼˜å…ˆè¿”å›target_pathï¼Œå¦‚æœä¸ºç©ºåˆ™è¿”å›original_path
	existingPath := fileInfo.TargetPath
	if existingPath == "" {
		existingPath = fileInfo.OriginalPath
	}
	
	return true, existingPath, nil
}

// InsertFileRecord æ’å…¥å•ä¸ªæ–‡ä»¶è®°å½•ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
func (db *Database) InsertFileRecord(fileInfo FileInfo) error {
	return db.BatchInsertFileRecord(fileInfo)
}

// BatchInsertFileRecord æ‰¹é‡æ’å…¥æ–‡ä»¶è®°å½•ï¼Œæé«˜æ’å…¥æ€§èƒ½
// å‚æ•°ï¼šfileInfo - æ–‡ä»¶ä¿¡æ¯è®°å½•
// è¿”å›ï¼šé”™è¯¯ä¿¡æ¯
// åŠŸèƒ½ï¼šå°†æ–‡ä»¶è®°å½•æ·»åŠ åˆ°æ‰¹é‡ç¼“å†²åŒºï¼Œè¾¾åˆ°æ‰¹é‡å¤§å°æ—¶è‡ªåŠ¨åˆ·æ–°
func (db *Database) BatchInsertFileRecord(fileInfo FileInfo) error {
	db.batchMutex.Lock()
	defer db.batchMutex.Unlock()

	// æ·»åŠ åˆ°æ‰¹é‡ç¼“å†²åŒº
	db.batchBuffer = append(db.batchBuffer, fileInfo)
	LogDebug("ğŸ“ æ·»åŠ æ–‡ä»¶è®°å½•åˆ°æ‰¹é‡ç¼“å†²åŒº: %s (ç¼“å†²åŒºå¤§å°: %d/%d)", 
		fileInfo.FileName, len(db.batchBuffer), db.batchSize)

	// æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°æ‰¹é‡ç¼“å†²åŒº
	if len(db.batchBuffer) >= db.batchSize {
		LogDebug("ğŸš€ æ‰¹é‡ç¼“å†²åŒºå·²æ»¡ï¼Œå¼€å§‹åˆ·æ–°...")
		if err := db.flushBatch(); err != nil {
			LogError("âŒ æ‰¹é‡åˆ·æ–°å¤±è´¥: %v", err)
			return err
		}
		LogInfo("âœ… æ‰¹é‡åˆ·æ–°å®Œæˆï¼Œå·²å¤„ç† %d æ¡è®°å½•", db.batchSize)
	}

	// é‡ç½®å®šæ—¶å™¨
	if db.batchTimer != nil {
		db.batchTimer.Reset(2 * time.Second) // 2ç§’åå¼ºåˆ¶æ‰§è¡Œæ‰¹é‡æ’å…¥
	}

	return nil
}

// flushBatch æ‰§è¡Œæ‰¹é‡æ’å…¥æ“ä½œ
func (db *Database) flushBatch() error {
	if len(db.batchBuffer) == 0 {
		return nil
	}

	startTime := time.Now()
	batchCount := len(db.batchBuffer)
	LogInfo("ğŸ’¾ å¼€å§‹æ‰¹é‡æ’å…¥æ•°æ®åº“è®°å½•: %d æ¡", batchCount)
	
	defer func() {
		duration := time.Since(startTime)
		if duration > 1*time.Second {
			LogWarn("âš ï¸ æ‰¹é‡æ•°æ®åº“æ’å…¥è€—æ—¶è¾ƒé•¿: %v (è®°å½•æ•°: %d)", duration, batchCount)
		} else {
			LogInfo("âœ… æ‰¹é‡æ•°æ®åº“æ’å…¥å®Œæˆ: %v (è®°å½•æ•°: %d)", duration, batchCount)
		}
	}()

	// æ„å»ºæ‰¹é‡æ’å…¥SQL
	query := `
		INSERT INTO file_records (
			hash, original_name, file_size, extension, created_at, 
			processed_at, source_path, target_path, hash_type
		) VALUES `

	// æ„å»ºVALUESå­å¥
	values := make([]interface{}, 0, len(db.batchBuffer)*9)
	placeholders := make([]string, 0, len(db.batchBuffer))
	
	for i, fileInfo := range db.batchBuffer {
		placeholderStart := i*9 + 1
		placeholders = append(placeholders, fmt.Sprintf("($%d, $%d, $%d, $%d, $%d, $%d, $%d, $%d, $%d)",
			placeholderStart, placeholderStart+1, placeholderStart+2, placeholderStart+3,
			placeholderStart+4, placeholderStart+5, placeholderStart+6, placeholderStart+7, placeholderStart+8))
		
		values = append(values,
			fileInfo.Hash,
			fileInfo.FileName,
			fileInfo.FileSize,
			fileInfo.Extension,
			fileInfo.CreatedAt,
			time.Now(),
			fileInfo.OriginalPath,
			fileInfo.NewPath,
			"sha256",
		)
	}

	// æ‰§è¡Œæ‰¹é‡æ’å…¥
	finalQuery := query + fmt.Sprintf("%s", placeholders[0])
	for i := 1; i < len(placeholders); i++ {
		finalQuery += ", " + placeholders[i]
	}

	_, err := db.db.Exec(finalQuery, values...)
	if err != nil {
		LogError("âŒ æ‰¹é‡æ’å…¥æ–‡ä»¶è®°å½•å¤±è´¥: %v", err)
		return fmt.Errorf("æ‰¹é‡æ’å…¥æ–‡ä»¶è®°å½•å¤±è´¥: %v", err)
	}

	// æ¸…ç©ºç¼“å†²åŒº
	db.batchBuffer = db.batchBuffer[:0]
	LogDebug("ğŸ§¹ æ‰¹é‡ç¼“å†²åŒºå·²æ¸…ç©º")
	
	return nil
}

// startBatchTimer å¯åŠ¨æ‰¹é‡å¤„ç†å®šæ—¶å™¨
func (db *Database) startBatchTimer() {
	db.batchTimer = time.AfterFunc(2*time.Second, func() {
		db.batchMutex.Lock()
		defer db.batchMutex.Unlock()
		
		if len(db.batchBuffer) > 0 {
			LogDebug("â° å®šæ—¶å™¨è§¦å‘æ‰¹é‡æ’å…¥: %d æ¡è®°å½•", len(db.batchBuffer))
			if err := db.flushBatch(); err != nil {
				LogError("âŒ å®šæ—¶æ‰¹é‡æ’å…¥å¤±è´¥: %v", err)
			}
		}
		
		// é‡æ–°å¯åŠ¨å®šæ—¶å™¨
		db.startBatchTimer()
	})
}

// FlushPendingBatch å¼ºåˆ¶æ‰§è¡Œæ‰€æœ‰å¾…å¤„ç†çš„æ‰¹é‡æ“ä½œ
func (db *Database) FlushPendingBatch() error {
	db.batchMutex.Lock()
	defer db.batchMutex.Unlock()
	
	return db.flushBatch()
}

// GetFileRecord æ ¹æ®å“ˆå¸Œå€¼è·å–æ–‡ä»¶è®°å½•
func (d *Database) GetFileRecord(hash string) (*FileInfo, error) {
	query := `
	SELECT id, hash, original_name, file_size, extension, created_at, processed_at, source_path, target_path, hash_type
	FROM file_records WHERE hash = $1
	`

	var fileInfo FileInfo
	err := d.db.QueryRow(query, hash).Scan(
		&fileInfo.ID,
		&fileInfo.Hash,
		&fileInfo.OriginalName,
		&fileInfo.FileSize,
		&fileInfo.Extension,
		&fileInfo.CreatedAt,
		&fileInfo.ProcessedAt,
		&fileInfo.SourcePath,
		&fileInfo.TargetPath,
		&fileInfo.HashType,
	)

	if err != nil {
		if err == sql.ErrNoRows {
			return nil, nil // è®°å½•ä¸å­˜åœ¨
		}
		return nil, fmt.Errorf("æŸ¥è¯¢æ–‡ä»¶è®°å½•å¤±è´¥: %v", err)
	}

	return &fileInfo, nil
}

// GetFilesByExtension æ ¹æ®æ‰©å±•åè·å–æ–‡ä»¶åˆ—è¡¨
func (d *Database) GetFilesByExtension(extension string, limit int) ([]*FileInfo, error) {
	query := `
	SELECT id, hash, original_name, file_size, extension, created_at, processed_at, source_path, target_path, hash_type
	FROM file_records 
	WHERE extension = $1 
	ORDER BY processed_at DESC 
	LIMIT $2
	`

	rows, err := d.db.Query(query, extension, limit)
	if err != nil {
		return nil, fmt.Errorf("æŸ¥è¯¢æ–‡ä»¶åˆ—è¡¨å¤±è´¥: %v", err)
	}
	defer rows.Close()

	var files []*FileInfo
	for rows.Next() {
		var fileInfo FileInfo
		err := rows.Scan(
			&fileInfo.ID,
			&fileInfo.Hash,
			&fileInfo.OriginalName,
			&fileInfo.FileSize,
			&fileInfo.Extension,
			&fileInfo.CreatedAt,
			&fileInfo.ProcessedAt,
			&fileInfo.SourcePath,
			&fileInfo.TargetPath,
			&fileInfo.HashType,
		)
		if err != nil {
			return nil, fmt.Errorf("æ‰«ææ–‡ä»¶è®°å½•å¤±è´¥: %v", err)
		}
		files = append(files, &fileInfo)
	}

	if err = rows.Err(); err != nil {
		return nil, fmt.Errorf("éå†æŸ¥è¯¢ç»“æœå¤±è´¥: %v", err)
	}

	return files, nil
}

// GetStatistics è·å–æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
func (d *Database) GetStatistics() (map[string]interface{}, error) {
	stats := make(map[string]interface{})

	// æ€»æ–‡ä»¶æ•°
	var totalFiles int
	err := d.db.QueryRow("SELECT COUNT(*) FROM file_records").Scan(&totalFiles)
	if err != nil {
		return nil, fmt.Errorf("æŸ¥è¯¢æ€»æ–‡ä»¶æ•°å¤±è´¥: %v", err)
	}
	stats["total_files"] = totalFiles

	// æ€»æ–‡ä»¶å¤§å°
	var totalSize sql.NullInt64
	err = d.db.QueryRow("SELECT SUM(file_size) FROM file_records").Scan(&totalSize)
	if err != nil {
		return nil, fmt.Errorf("æŸ¥è¯¢æ€»æ–‡ä»¶å¤§å°å¤±è´¥: %v", err)
	}
	if totalSize.Valid {
		stats["total_size"] = totalSize.Int64
	} else {
		stats["total_size"] = 0
	}

	// æŒ‰æ‰©å±•åç»Ÿè®¡
	extQuery := `
	SELECT extension, COUNT(*), SUM(file_size) 
	FROM file_records 
	GROUP BY extension 
	ORDER BY COUNT(*) DESC
	`
	rows, err := d.db.Query(extQuery)
	if err != nil {
		return nil, fmt.Errorf("æŸ¥è¯¢æ‰©å±•åç»Ÿè®¡å¤±è´¥: %v", err)
	}
	defer rows.Close()

	extStats := make(map[string]map[string]interface{})
	for rows.Next() {
		var ext string
		var count int
		var size sql.NullInt64

		err := rows.Scan(&ext, &count, &size)
		if err != nil {
			return nil, fmt.Errorf("æ‰«ææ‰©å±•åç»Ÿè®¡å¤±è´¥: %v", err)
		}

		extInfo := map[string]interface{}{
			"count": count,
		}
		if size.Valid {
			extInfo["size"] = size.Int64
		} else {
			extInfo["size"] = 0
		}
		extStats[ext] = extInfo
	}
	stats["by_extension"] = extStats

	return stats, nil
}

// DeleteFileRecord åˆ é™¤æ–‡ä»¶è®°å½•
func (db *Database) DeleteFileRecord(hash string) error {
	LogDebug("ğŸ—‘ï¸ æ­£åœ¨åˆ é™¤æ–‡ä»¶è®°å½•: %s", hash[:12]+"...")
	query := "DELETE FROM file_records WHERE hash = $1"
	result, err := db.db.Exec(query, hash)
	if err != nil {
		LogError("âŒ åˆ é™¤æ–‡ä»¶è®°å½•å¤±è´¥: %v", err)
		return fmt.Errorf("åˆ é™¤æ–‡ä»¶è®°å½•å¤±è´¥: %v", err)
	}
	
	rowsAffected, err := result.RowsAffected()
	if err != nil {
		LogError("âŒ è·å–åˆ é™¤ç»“æœå¤±è´¥: %v", err)
		return fmt.Errorf("è·å–åˆ é™¤ç»“æœå¤±è´¥: %v", err)
	}
	
	if rowsAffected > 0 {
		LogInfo("âœ… æ–‡ä»¶è®°å½•å·²åˆ é™¤: %s", hash[:12]+"...")
	} else {
		LogWarn("âš ï¸ æœªæ‰¾åˆ°è¦åˆ é™¤çš„æ–‡ä»¶è®°å½•: %s", hash[:12]+"...")
	}
	
	return nil
}

// Close å…³é—­æ•°æ®åº“è¿æ¥
func (d *Database) Close() error {
	if d.db != nil {
		return d.db.Close()
	}
	return nil
}

// Ping æµ‹è¯•æ•°æ®åº“è¿æ¥
func (d *Database) Ping() error {
	return d.db.Ping()
}
