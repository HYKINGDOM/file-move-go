// æ–‡ä»¶å¤„ç†æ¨¡å— - é«˜æ€§èƒ½æ–‡ä»¶å¤„ç†å¼•æ“ï¼Œæ”¯æŒæ™ºèƒ½è´Ÿè½½å‡è¡¡å’Œå¹¶å‘å¤„ç†
// åŠŸèƒ½ï¼šæ–‡ä»¶å“ˆå¸Œè®¡ç®—ã€é‡å¤æ£€æµ‹ã€æ™ºèƒ½ç§»åŠ¨ã€æ‰¹é‡å¤„ç†
// ç‰¹æ€§ï¼šæ™ºèƒ½è´Ÿè½½å‡è¡¡ã€ç›®å½•ç¼“å­˜ã€æ€§èƒ½ç»Ÿè®¡ã€é”™è¯¯å¤„ç†ã€è¿›åº¦ç›‘æ§
package main

import (
	"crypto/md5"
	"crypto/sha256"
	"fmt"
	"hash"
	"io"
	"os"
	"path/filepath"
	"runtime"
	"strings"
	"sync"
	"sync/atomic"
	"time"
)

// FileProcessor æ–‡ä»¶å¤„ç†å™¨ï¼Œæ”¯æŒæ™ºèƒ½è´Ÿè½½å‡è¡¡å’Œä¼˜åŒ–çš„å¹¶å‘å¤„ç†
// æ ¸å¿ƒç»„ä»¶ï¼šè´Ÿè´£æ–‡ä»¶çš„å“ˆå¸Œè®¡ç®—ã€é‡å¤æ£€æµ‹ã€æ™ºèƒ½ç§»åŠ¨ç­‰æ ¸å¿ƒåŠŸèƒ½
type FileProcessor struct {
	config   *Config   // é…ç½®ä¿¡æ¯
	database *Database // æ•°æ®åº“è¿æ¥
	mutex    sync.RWMutex // è¯»å†™äº’æ–¥é”ï¼Œä¿æŠ¤å…±äº«èµ„æº
	stats    ProcessorStats // å¤„ç†ç»Ÿè®¡ä¿¡æ¯

	// æ™ºèƒ½è´Ÿè½½å‡è¡¡ç›¸å…³å­—æ®µ
	workerLoad []int64      // æ¯ä¸ªå·¥ä½œåç¨‹çš„è´Ÿè½½è®¡æ•°ï¼Œç”¨äºè´Ÿè½½å‡è¡¡
	loadMutex  sync.RWMutex // è´Ÿè½½ç»Ÿè®¡äº’æ–¥é”ï¼Œä¿æŠ¤è´Ÿè½½æ•°æ®

	// ç›®å½•ç¼“å­˜ç›¸å…³å­—æ®µï¼Œæé«˜ç›®å½•æ“ä½œæ€§èƒ½
	dirCache       map[string]bool // ç›®å½•å­˜åœ¨æ€§ç¼“å­˜ï¼Œé¿å…é‡å¤æ£€æŸ¥
	dirCacheMutex  sync.RWMutex    // ç›®å½•ç¼“å­˜äº’æ–¥é”

	// é˜Ÿåˆ—ç®¡ç†å­—æ®µ
	queueSize    int64 // å½“å‰é˜Ÿåˆ—å¤§å°ï¼Œç”¨äºæµé‡æ§åˆ¶
	maxQueueSize int64 // æœ€å¤§é˜Ÿåˆ—å¤§å°ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º

	// æ€§èƒ½ç»Ÿè®¡å­—æ®µ
	totalProcessTime int64 // æ€»å¤„ç†æ—¶é—´ï¼ˆçº³ç§’ï¼‰ï¼Œç”¨äºæ€§èƒ½åˆ†æ
	processedCount   int64 // å·²å¤„ç†æ–‡ä»¶è®¡æ•°ï¼ŒåŸå­æ“ä½œä¿è¯çº¿ç¨‹å®‰å…¨
}

// ProcessorStats å¤„ç†å™¨ç»Ÿè®¡ä¿¡æ¯ç»“æ„ä½“
// ç”¨äºè®°å½•å’Œå±•ç¤ºæ–‡ä»¶å¤„ç†çš„å„é¡¹ç»Ÿè®¡æ•°æ®
type ProcessorStats struct {
	ProcessedFiles int64     // å·²å¤„ç†æ–‡ä»¶æ•°é‡
	MovedFiles     int64     // å·²ç§»åŠ¨æ–‡ä»¶æ•°é‡
	DeletedFiles   int64     // å·²åˆ é™¤é‡å¤æ–‡ä»¶æ•°é‡
	ErrorCount     int64     // é”™è¯¯è®¡æ•°
	TotalSize      int64     // æ€»å¤„ç†æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
	StartTime      time.Time // å¤„ç†å¼€å§‹æ—¶é—´
}

// NewFileProcessor åˆ›å»ºæ–°çš„æ–‡ä»¶å¤„ç†å™¨ï¼Œæ”¯æŒæ™ºèƒ½è´Ÿè½½å‡è¡¡
// å‚æ•°ï¼šconfig - é…ç½®ä¿¡æ¯ï¼Œdatabase - æ•°æ®åº“è¿æ¥
// è¿”å›ï¼šæ–‡ä»¶å¤„ç†å™¨å®ä¾‹
// åŠŸèƒ½ï¼šåˆå§‹åŒ–å¤„ç†å™¨ï¼Œé…ç½®å¹¶å‘å‚æ•°ï¼Œè®¾ç½®è´Ÿè½½å‡è¡¡
func NewFileProcessor(config *Config, database *Database) *FileProcessor {
	// æ ¹æ®ç³»ç»Ÿèµ„æºåŠ¨æ€è°ƒæ•´å¹¶å‘æ•°ï¼Œä¼˜åŒ–æ€§èƒ½
	if config.ConcurrentWorkers <= 0 {
		config.ConcurrentWorkers = runtime.NumCPU() * 2 // é»˜è®¤ä¸ºCPUæ ¸å¿ƒæ•°çš„2å€ï¼Œå¹³è¡¡CPUå’ŒI/O
		LogInfo("ğŸ”§ è‡ªåŠ¨è®¾ç½®å¹¶å‘å·¥ä½œåç¨‹æ•°: %d (CPUæ ¸å¿ƒæ•°: %d)", config.ConcurrentWorkers, runtime.NumCPU())
	}

	// åˆå§‹åŒ–å·¥ä½œåç¨‹è´Ÿè½½ç»Ÿè®¡æ•°ç»„
	workerLoad := make([]int64, config.ConcurrentWorkers)

	// åˆå§‹åŒ–ç›®å½•ç¼“å­˜
	dirCache := make(map[string]bool)

	// è®¾ç½®é˜Ÿåˆ—å¤§å°
	maxQueueSize := int64(config.ConcurrentWorkers * 50)

	return &FileProcessor{
		config:        config,
		database:      database,
		stats:         ProcessorStats{StartTime: time.Now()},
		workerLoad:    workerLoad,
		dirCache:      dirCache,
		maxQueueSize:  maxQueueSize,
		queueSize:     0,
	}
}
// ProcessExistingFiles å¤„ç†ç°æœ‰æ–‡ä»¶ï¼Œä½¿ç”¨ä¼˜åŒ–çš„å¹¶å‘å’Œé˜Ÿåˆ—ç®¡ç†
func (fp *FileProcessor) ProcessExistingFiles() error {
	LogInfo("å¼€å§‹æ‰«ææºæ–‡ä»¶å¤¹: %s", fp.config.SourceFolder)
	LogInfo("é…ç½®ä¿¡æ¯ - å¹¶å‘å·¥ä½œè€…: %d, æœ€å¤§æ–‡ä»¶å¤§å°: %s, å“ˆå¸Œç®—æ³•: %s",
		fp.config.ConcurrentWorkers,
		formatFileSize(int64(fp.config.MaxFileSize)),
		fp.config.HashAlgorithm)

	// åˆ›å»ºåŠ¨æ€è°ƒæ•´çš„é€šé“
	channelSize := fp.config.ConcurrentWorkers * 50 // åŠ¨æ€è°ƒæ•´ç¼“å†²åŒºå¤§å°
	fileChan := make(chan string, channelSize)
	errorChan := make(chan error, fp.config.ConcurrentWorkers)


	// å¯åŠ¨è´Ÿè½½ç›‘æ§åç¨‹
	loadMonitorDone := make(chan bool)
	go fp.monitorWorkerLoad(loadMonitorDone)

	// å¯åŠ¨è¿›åº¦æ˜¾ç¤ºåç¨‹
	progressDone := make(chan bool)
	go fp.showProgress(progressDone)

	// å¯åŠ¨æ™ºèƒ½å·¥ä½œåç¨‹
	var wg sync.WaitGroup
	for i := 0; i < fp.config.ConcurrentWorkers; i++ {
		wg.Add(1)
		go fp.smartWorker(i, fileChan, errorChan, &wg)
	}

	totalFiles := 0
	skippedFiles := 0
	processedFiles := 0
	queueFullCount := 0

	err := filepath.Walk(fp.config.SourceFolder, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			LogError("è®¿é—®æ–‡ä»¶å¤±è´¥ %s: %v", path, err)
			return nil
		}

		// è·³è¿‡ç›®å½•
		if info.IsDir() {
			return nil
		}

		totalFiles++

		// æ£€æŸ¥æ–‡ä»¶ç±»å‹
		if !fp.config.IsSupportedFile(path) {
			skippedFiles++
			return nil
		}

		// æ£€æŸ¥æ–‡ä»¶å¤§å°
		if info.Size() > int64(fp.config.MaxFileSize) {
			skippedFiles++
			LogDebug("æ–‡ä»¶è¿‡å¤§ï¼Œè·³è¿‡: %s (å¤§å°: %d å­—èŠ‚)", path, info.Size())
			return nil
		}

		// æ™ºèƒ½é˜Ÿåˆ—ç®¡ç† - æ£€æŸ¥é˜Ÿåˆ—è´Ÿè½½
		currentQueueSize := atomic.LoadInt64(&fp.queueSize)
		if currentQueueSize >= fp.maxQueueSize {
			queueFullCount++
			if queueFullCount%100 == 0 { // æ¯100æ¬¡è®°å½•ä¸€æ¬¡
				LogWarn("é˜Ÿåˆ—è´Ÿè½½è¿‡é«˜ï¼Œç­‰å¾…å¤„ç†: å½“å‰é˜Ÿåˆ—=%d, æœ€å¤§é˜Ÿåˆ—=%d", currentQueueSize, fp.maxQueueSize)
			}

			// ç­‰å¾…é˜Ÿåˆ—æœ‰ç©ºé—´
			for atomic.LoadInt64(&fp.queueSize) >= fp.maxQueueSize {
				time.Sleep(10 * time.Millisecond)
			}
		}

		select {
		case fileChan <- path:
			atomic.AddInt64(&fp.queueSize, 1)
			processedFiles++
		default:
			LogWarn("å¤„ç†é˜Ÿåˆ—å·²æ»¡ï¼Œè·³è¿‡æ–‡ä»¶: %s", path)
			skippedFiles++
		}

		return nil
	})

	if err != nil {
		LogError("éå†æ–‡ä»¶å¤¹å¤±è´¥: %v", err)
		close(fileChan)
		progressDone <- true
		loadMonitorDone <- true
		return err
	}

	// å…³é—­æ–‡ä»¶é€šé“ï¼Œç­‰å¾…å¤„ç†å®Œæˆ
	close(fileChan)
	LogInfo("æ–‡ä»¶å¤¹éå†å®Œæˆ - æ€»æ–‡ä»¶æ•°: %d, è·³è¿‡æ–‡ä»¶æ•°: %d, å¾…å¤„ç†æ–‡ä»¶æ•°: %d",
		totalFiles, skippedFiles, processedFiles)

	if queueFullCount > 0 {
		LogInfo("é˜Ÿåˆ—æ»¡è½½æ¬¡æ•°: %d (å·²ä¼˜åŒ–å¤„ç†)", queueFullCount)
	}

	// ç­‰å¾…æ‰€æœ‰å·¥ä½œåç¨‹å®Œæˆ
	wg.Wait()

	progressDone <- true
	loadMonitorDone <- true

	// å¼ºåˆ¶æ‰§è¡Œæ•°æ®åº“æ‰¹é‡æ“ä½œ
	if err := fp.database.FlushPendingBatch(); err != nil {
		LogError("åˆ·æ–°æ•°æ®åº“æ‰¹é‡æ“ä½œå¤±è´¥: %v", err)
	}

	// å¤„ç†é”™è¯¯
	close(errorChan)
	var errors []error
	for err := range errorChan {
		errors = append(errors, err)
	}

	if len(errors) == 0 {
		LogInfo("å¤„ç†å®Œæˆï¼Œå¼€å§‹æ‰“å°ç»Ÿè®¡ä¿¡æ¯...")
		fp.printStats()
	} else {
		LogError("å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿ %d ä¸ªé”™è¯¯", len(errors))
		for _, err := range errors {
			LogError("é”™è¯¯: %v", err)
		}
	}

	return nil

}

func (fp *FileProcessor) smartWorker(workerID int, fileChan <-chan string, errorChan chan<- error, wg *sync.WaitGroup) {
	defer wg.Done()
	LogInfo("æ™ºèƒ½å·¥ä½œåç¨‹ #%d å¯åŠ¨", workerID)
	processedCount := 0

	for filePath := range fileChan {
		startTime := time.Now()

		// å‡å°‘é˜Ÿåˆ—è®¡æ•°
		atomic.AddInt64(&fp.queueSize, -1)

		// å¤„ç†æ–‡ä»¶
		if err := fp.ProcessFile(filePath); err != nil {
			select {
			case errorChan <- fmt.Errorf("å·¥ä½œåç¨‹ #%d å¤„ç†æ–‡ä»¶å¤±è´¥ %s: %v", workerID, filePath, err):
			default:
				LogError("å·¥ä½œåç¨‹ #%d å¤„ç†æ–‡ä»¶å¤±è´¥ %s: %v", workerID, filePath, err)
			}
		}

		processingTime := time.Since(startTime)
		atomic.AddInt64(&fp.workerLoad[workerID], processingTime.Nanoseconds())
		atomic.AddInt64(&fp.totalProcessTime, processingTime.Nanoseconds())
		atomic.AddInt64(&fp.processedCount, 1)

		processedCount++

		// æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
		fp.incrementProcessedFiles()
	}

	LogInfo("æ™ºèƒ½å·¥ä½œåç¨‹ #%d å®Œæˆï¼Œå¤„ç†æ–‡ä»¶æ•°: %d", workerID, processedCount)
}

// monitorWorkerLoad ç›‘æ§å·¥ä½œåç¨‹è´Ÿè½½
func (fp *FileProcessor) monitorWorkerLoad(done <-chan bool) {
	ticker := time.NewTicker(30 * time.Second) // æ¯30ç§’ç›‘æ§ä¸€æ¬¡

	for {
		select {
		case <-ticker.C:
			fp.logWorkerLoadStats()
		case <-done:
			fp.logWorkerLoadStats() // æœ€åä¸€æ¬¡ç»Ÿè®¡
			return
		}
	}
}

// logWorkerLoadStats è®°å½•å·¥ä½œåç¨‹è´Ÿè½½ç»Ÿè®¡
func (fp *FileProcessor) logWorkerLoadStats() {
	fp.loadMutex.RLock()
	defer fp.loadMutex.RUnlock()

	totalLoad := int64(0)
	maxLoad := int64(0)
	minLoad := int64(^uint64(0) >> 1) // æœ€å¤§int64å€¼

	for _, load := range fp.workerLoad {
		totalLoad += load
		if load > maxLoad {
			maxLoad = load
		}
		if load < minLoad {
			minLoad = load
		}
	}

	if len(fp.workerLoad) > 0 {
		avgLoad := totalLoad / int64(len(fp.workerLoad))
		processedCount := atomic.LoadInt64(&fp.processedCount)

		if processedCount > 0 {
			avgProcessTime := time.Duration(atomic.LoadInt64(&fp.totalProcessTime) / processedCount)
			LogDebug("ğŸ“Š è´Ÿè½½å‡è¡¡ç»Ÿè®¡ - å¹³å‡è´Ÿè½½: %v, æœ€å¤§è´Ÿè½½: %v, æœ€å°è´Ÿè½½: %v, å¹³å‡å¤„ç†æ—¶é—´: %v",
				time.Duration(avgLoad), time.Duration(maxLoad), time.Duration(minLoad), avgProcessTime)
		}
	}

	currentQueueSize := atomic.LoadInt64(&fp.queueSize)
	LogDebug("ğŸ“Š é˜Ÿåˆ—çŠ¶æ€ - å½“å‰é˜Ÿåˆ—: %d, æœ€å¤§é˜Ÿåˆ—: %d, åˆ©ç”¨ç‡: %.1f%%",
		currentQueueSize, fp.maxQueueSize, float64(currentQueueSize)/float64(fp.maxQueueSize)*100)
}

// ensureDirectoryExists ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œä½¿ç”¨ç¼“å­˜ä¼˜åŒ–
func (fp *FileProcessor) ensureDirectoryExists(dirPath string) error {
	// æ£€æŸ¥ç¼“å­˜
	fp.dirCacheMutex.RLock()
	if exists, found := fp.dirCache[dirPath]; found && exists {
		fp.dirCacheMutex.RUnlock()
		return nil
	}
	fp.dirCacheMutex.RUnlock()

	// åˆ›å»ºç›®å½•
	if err := os.MkdirAll(dirPath, 0755); err != nil {
		return err
	}

	// æ›´æ–°ç¼“å­˜
	fp.dirCacheMutex.Lock()
	fp.dirCache[dirPath] = true
	fp.dirCacheMutex.Unlock()

	return nil
}

// ProcessFile å¤„ç†å•ä¸ªæ–‡ä»¶
func (fp *FileProcessor) ProcessFile(filePath string) error {
	startTime := time.Now()
	defer func() {
		totalDuration := time.Since(startTime)
		LogDebug("â±ï¸ æ–‡ä»¶å¤„ç†æ€»è€—æ—¶: %s -> %v", filepath.Base(filePath), totalDuration)
	}()

	// è·å–æ–‡ä»¶ä¿¡æ¯
	fileInfoStart := time.Now()
	fileInfo, err := os.Stat(filePath)
	if err != nil {
		LogError("âŒ è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: %s - %v", filePath, err)
		return fmt.Errorf("è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: %v", err)
	}
	LogDebug("â±ï¸ è·å–æ–‡ä»¶ä¿¡æ¯è€—æ—¶: %v", time.Since(fileInfoStart))

	// è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
	hashStart := time.Now()
	hash, err := fp.calculateFileHash(filePath)
	if err != nil {
		LogError("âŒ è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥: %s - %v", filePath, err)
		return fmt.Errorf("è®¡ç®—æ–‡ä»¶å“ˆå¸Œå¤±è´¥: %v", err)
	}
	hashDuration := time.Since(hashStart)
	LogDebug("â±ï¸ å“ˆå¸Œè®¡ç®—è€—æ—¶: %v (æ–‡ä»¶å¤§å°: %s)", hashDuration, formatFileSize(fileInfo.Size()))

	// æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
	dbCheckStart := time.Now()
	exists, existingPath, err := fp.database.FileExists(hash)
	if err != nil {
		LogError("âŒ æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: %s - %v", hash, err)
		return fmt.Errorf("æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: %v", err)
	}
	LogDebug("â±ï¸ æ•°æ®åº“æŸ¥è¯¢è€—æ—¶: %v", time.Since(dbCheckStart))

	if exists {
		// æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ é™¤é‡å¤æ–‡ä»¶
		deleteStart := time.Now()
		if err := os.Remove(filePath); err != nil {
			LogError("âŒ åˆ é™¤é‡å¤æ–‡ä»¶å¤±è´¥: %s - %v", filePath, err)
			return fmt.Errorf("åˆ é™¤é‡å¤æ–‡ä»¶å¤±è´¥: %v", err)
		}
		LogDebug("â±ï¸ åˆ é™¤é‡å¤æ–‡ä»¶è€—æ—¶: %v", time.Since(deleteStart))
		LogInfo("ğŸ—‘ï¸ åˆ é™¤é‡å¤æ–‡ä»¶: %s (å·²å­˜åœ¨: %s)", filepath.Base(filePath), existingPath)
		fp.incrementDeletedFiles()
		fp.addTotalSize(fileInfo.Size())
		return nil
	}

	// ç§»åŠ¨æ–‡ä»¶åˆ°ç›®æ ‡ä½ç½®
	moveStart := time.Now()
	targetPath, err := fp.moveFileToTarget(filePath, filepath.Base(filePath))
	if err != nil {
		LogError("âŒ ç§»åŠ¨æ–‡ä»¶å¤±è´¥: %s - %v", filePath, err)
		return fmt.Errorf("ç§»åŠ¨æ–‡ä»¶å¤±è´¥: %v", err)
	}
	moveDuration := time.Since(moveStart)
	LogDebug("â±ï¸ æ–‡ä»¶ç§»åŠ¨æ€»è€—æ—¶: %v -> %s", moveDuration, filepath.Base(targetPath))

	// æ’å…¥æ•°æ®åº“è®°å½•
	dbInsertStart := time.Now()
	fileRecord := FileInfo{
		Hash:         hash,
		OriginalPath: filePath,
		NewPath:      targetPath,
		FileName:     filepath.Base(filePath),
		FileSize:     fileInfo.Size(),
		Extension:    strings.ToLower(filepath.Ext(filePath)),
		CreatedAt:    time.Now(),
	}

	if err := fp.database.InsertFileRecord(fileRecord); err != nil {
		// å¦‚æœæ•°æ®åº“æ’å…¥å¤±è´¥ï¼Œå°è¯•æ¢å¤æ–‡ä»¶
		LogWarn("âš ï¸ æ•°æ®åº“æ’å…¥å¤±è´¥ï¼Œå°è¯•æ¢å¤æ–‡ä»¶: %s", targetPath)
		if moveErr := os.Rename(targetPath, filePath); moveErr != nil {
			LogError("âŒ æ¢å¤æ–‡ä»¶å¤±è´¥: %s -> %s - %v", targetPath, filePath, moveErr)
		} else {
			LogInfo("âœ… æ–‡ä»¶æ¢å¤æˆåŠŸ: %s", filePath)
		}
		LogError("âŒ æ’å…¥æ•°æ®åº“è®°å½•å¤±è´¥: %v", err)
		return fmt.Errorf("æ’å…¥æ•°æ®åº“è®°å½•å¤±è´¥: %v", err)
	}
	LogDebug("â±ï¸ æ•°æ®åº“æ’å…¥è€—æ—¶: %v", time.Since(dbInsertStart))

	LogInfo("âœ… æ–‡ä»¶å¤„ç†æˆåŠŸ: %s -> %s", filepath.Base(filePath), filepath.Base(targetPath))
	fp.incrementMovedFiles()
	fp.addTotalSize(fileInfo.Size())
	return nil
}

// calculateFileHash è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼
func (fp *FileProcessor) calculateFileHash(filePath string) (string, error) {
	startTime := time.Now()
	defer func() {
		duration := time.Since(startTime)
		LogDebug("â±ï¸ å“ˆå¸Œè®¡ç®—è€—æ—¶: %v", duration)
	}()

	// æ‰“å¼€æ–‡ä»¶
	file, err := os.Open(filePath)
	if err != nil {
		return "", fmt.Errorf("æ‰“å¼€æ–‡ä»¶å¤±è´¥: %v", err)
	}
	defer file.Close()

	// æ ¹æ®é…ç½®é€‰æ‹©å“ˆå¸Œç®—æ³•
	var hasher hash.Hash
	switch strings.ToLower(fp.config.HashAlgorithm) {
	case "md5":
		hasher = md5.New()
	case "sha256":
		hasher = sha256.New()
	default:
		hasher = sha256.New() // é»˜è®¤ä½¿ç”¨SHA256
		LogWarn("âš ï¸ æœªçŸ¥çš„å“ˆå¸Œç®—æ³• '%s'ï¼Œä½¿ç”¨é»˜è®¤çš„ SHA256", fp.config.HashAlgorithm)
	}

	// ä½¿ç”¨ç¼“å†²åŒºè¯»å–æ–‡ä»¶å†…å®¹å¹¶è®¡ç®—å“ˆå¸Œ
	buffer := make([]byte, 64*1024) // 64KBç¼“å†²åŒº
	for {
		n, err := file.Read(buffer)
		if err != nil && err != io.EOF {
			return "", fmt.Errorf("è¯»å–æ–‡ä»¶å¤±è´¥: %v", err)
		}
		if n == 0 {
			break
		}
		hasher.Write(buffer[:n])
	}

	// è¿”å›åå…­è¿›åˆ¶å“ˆå¸Œå€¼
	hashValue := fmt.Sprintf("%x", hasher.Sum(nil))
	LogDebug("ğŸ” æ–‡ä»¶å“ˆå¸Œè®¡ç®—å®Œæˆ: %s -> %s", filepath.Base(filePath), hashValue[:16]+"...")
	return hashValue, nil
}

// moveFileToTarget ç§»åŠ¨æ–‡ä»¶åˆ°ç›®æ ‡ä½ç½®
func (fp *FileProcessor) moveFileToTarget(sourcePath, fileName string) (string, error) {
	// æ ¹æ®å½“å‰æ—¥æœŸåˆ›å»ºç›®æ ‡ç›®å½•ç»“æ„
	now := time.Now()
	targetDir := filepath.Join(fp.config.TargetFolder, 
		fmt.Sprintf("%04d", now.Year()),
		fmt.Sprintf("%02d", now.Month()),
		fmt.Sprintf("%02d", now.Day()))

	// ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
	if err := fp.ensureDirectoryExists(targetDir); err != nil {
		return "", fmt.Errorf("åˆ›å»ºç›®æ ‡ç›®å½•å¤±è´¥: %v", err)
	}

	// æ„å»ºç›®æ ‡æ–‡ä»¶è·¯å¾„
	targetPath := filepath.Join(targetDir, fileName)

	// å¤„ç†æ–‡ä»¶åå†²çª
	counter := 1
	originalTargetPath := targetPath
	for {
		if _, err := os.Stat(targetPath); os.IsNotExist(err) {
			break // æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¯ä»¥ä½¿ç”¨è¿™ä¸ªè·¯å¾„
		}
		
		// æ–‡ä»¶å·²å­˜åœ¨ï¼Œç”Ÿæˆæ–°çš„æ–‡ä»¶å
		ext := filepath.Ext(fileName)
		nameWithoutExt := strings.TrimSuffix(fileName, ext)
		newFileName := fmt.Sprintf("%s_%d%s", nameWithoutExt, counter, ext)
		targetPath = filepath.Join(targetDir, newFileName)
		counter++
		
		// é˜²æ­¢æ— é™å¾ªç¯
		if counter > 1000 {
			return "", fmt.Errorf("æ— æ³•ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åï¼Œå·²å°è¯• %d æ¬¡", counter)
		}
	}

	// è®°å½•æ–‡ä»¶åå†²çªå¤„ç†
	if targetPath != originalTargetPath {
		LogInfo("ğŸ“ æ–‡ä»¶åå†²çªå¤„ç†: %s -> %s", filepath.Base(originalTargetPath), filepath.Base(targetPath))
	}

	// è·å–æºæ–‡ä»¶ä¿¡æ¯ç”¨äºæ€§èƒ½ç»Ÿè®¡
	srcInfo, err := os.Stat(sourcePath)
	if err != nil {
		return "", fmt.Errorf("è·å–æºæ–‡ä»¶ä¿¡æ¯å¤±è´¥: %v", err)
	}
	fileSize := srcInfo.Size()

	// å°è¯•åŸå­ç§»åŠ¨æ“ä½œï¼ˆåŒåˆ†åŒºå†…çš„å¿«é€Ÿç§»åŠ¨ï¼‰
	moveStart := time.Now()
	err = os.Rename(sourcePath, targetPath)
	moveDuration := time.Since(moveStart)

	if err != nil {
		// åŸå­ç§»åŠ¨å¤±è´¥ï¼Œå¯èƒ½æ˜¯è·¨åˆ†åŒºï¼Œä½¿ç”¨å¤åˆ¶+åˆ é™¤æ–¹å¼
		LogWarn("âš ï¸ åŸå­ç§»åŠ¨å¤±è´¥ï¼Œä½¿ç”¨å¤åˆ¶+åˆ é™¤æ–¹å¼: %v", err)

		// æ‰§è¡Œæ–‡ä»¶å¤åˆ¶
		copyStart := time.Now()
		if err := fp.copyFile(sourcePath, targetPath); err != nil {
			return "", fmt.Errorf("å¤åˆ¶æ–‡ä»¶å¤±è´¥: %v", err)
		}
		copyDuration := time.Since(copyStart)

		// è®¡ç®—å¤åˆ¶é€Ÿåº¦
		copySpeed := float64(fileSize) / copyDuration.Seconds() / (1024 * 1024) // MB/s
		LogDebug("â±ï¸ æ–‡ä»¶å¤åˆ¶å®Œæˆ: è€—æ—¶=%v, å¤§å°=%s, é€Ÿåº¦=%.2f MB/s",
			copyDuration, formatFileSize(fileSize), copySpeed)

		// åˆ é™¤æºæ–‡ä»¶
		deleteStart := time.Now()
		if err := os.Remove(sourcePath); err != nil {
			// å¤åˆ¶æˆåŠŸä½†åˆ é™¤å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ä¸è¿”å›å¤±è´¥
			LogError("âš ï¸ åˆ é™¤æºæ–‡ä»¶å¤±è´¥: %v (ç›®æ ‡æ–‡ä»¶å·²åˆ›å»º: %s)", err, targetPath)
		} else {
			LogDebug("â±ï¸ æºæ–‡ä»¶åˆ é™¤è€—æ—¶: %v", time.Since(deleteStart))
		}

		LogInfo("âœ… è·¨åˆ†åŒºæ–‡ä»¶ç§»åŠ¨å®Œæˆ: %s -> %s", filepath.Base(sourcePath), filepath.Base(targetPath))
	} else {
		// åŸå­ç§»åŠ¨æˆåŠŸ
		moveSpeed := float64(fileSize) / moveDuration.Seconds() / (1024 * 1024) // MB/s
		LogInfo("âš¡ åŸå­ç§»åŠ¨æˆåŠŸ: è€—æ—¶=%v, å¤§å°=%s, é€Ÿåº¦=%.2f MB/s",
			moveDuration, formatFileSize(fileSize), moveSpeed)
		LogInfo("âœ… åŒåˆ†åŒºæ–‡ä»¶ç§»åŠ¨å®Œæˆ: %s -> %s", filepath.Base(sourcePath), filepath.Base(targetPath))
	}

	return targetPath, nil
}

// copyFile å¤åˆ¶æ–‡ä»¶
func (fp *FileProcessor) copyFile(src, dst string) error {
	startTime := time.Now()
	defer func() {
		totalDuration := time.Since(startTime)
		LogInfo("â±ï¸ æ–‡ä»¶å¤åˆ¶æ€»è€—æ—¶: %v", totalDuration)
	}()

	// æ‰“å¼€æºæ–‡ä»¶
	openSrcStart := time.Now()
	srcFile, err := os.Open(src)
	if err != nil {
		return err
	}
	defer srcFile.Close()
	LogInfo("â±ï¸ æ‰“å¼€æºæ–‡ä»¶è€—æ—¶: %v", time.Since(openSrcStart))

	// åˆ›å»ºç›®æ ‡æ–‡ä»¶
	createDstStart := time.Now()
	dstFile, err := os.Create(dst)
	if err != nil {
		return err
	}
	defer dstFile.Close()
	LogInfo("â±ï¸ åˆ›å»ºç›®æ ‡æ–‡ä»¶è€—æ—¶: %v", time.Since(createDstStart))

	// è·å–æºæ–‡ä»¶ä¿¡æ¯
	srcInfo, err := srcFile.Stat()
	if err != nil {
		return err
	}
	fileSize := srcInfo.Size()

	// å¤åˆ¶æ–‡ä»¶å†…å®¹ï¼Œä½¿ç”¨1MBç¼“å†²åŒºæå‡æ€§èƒ½
	copyStart := time.Now()
	buffer := make([]byte, 1024*1024) // 1MBç¼“å†²åŒº
	_, err = io.CopyBuffer(dstFile, srcFile, buffer)
	if err != nil {
		return err
	}
	copyDuration := time.Since(copyStart)

	// è®¡ç®—å¤åˆ¶é€Ÿåº¦
	speed := float64(fileSize) / copyDuration.Seconds() / (1024 * 1024) // MB/s

	LogInfo("â±ï¸ æ–‡ä»¶å¤åˆ¶è¯¦æƒ…: è€—æ—¶=%v, å¤§å°=%s, é€Ÿåº¦=%.2f MB/s",
		copyDuration, formatFileSize(fileSize), speed)

	// å¤åˆ¶æ–‡ä»¶æƒé™
	chmodStart := time.Now()
	if err := os.Chmod(dst, srcInfo.Mode()); err != nil {
		return err
	}
	LogInfo("â±ï¸ æƒé™å¤åˆ¶è€—æ—¶: %v", time.Since(chmodStart))

	return nil
}

// PreCreateDirectories æ‰¹é‡é¢„åˆ›å»ºç›®å½•ç»“æ„
func (fp *FileProcessor) PreCreateDirectories() error {
	LogInfo("ğŸš€ å¼€å§‹æ‰¹é‡é¢„åˆ›å»ºç›®å½•ç»“æ„...")
	startTime := time.Now()

	// è·å–æ‰€æœ‰æ”¯æŒçš„æ–‡ä»¶ç±»å‹
	supportedTypes := fp.config.SupportedTypes
	createdDirs := make([]string, 0, len(supportedTypes))

	// ä¸ºæ¯ç§æ–‡ä»¶ç±»å‹åˆ›å»ºç›®å½•
	for _, ext := range supportedTypes {
		// å»æ‰æ‰©å±•åçš„ç‚¹å·
		dirName := ext[1:]
		targetDir := filepath.Join(fp.config.TargetFolder, dirName)

		// åˆ›å»ºç›®å½•
		if err := os.MkdirAll(targetDir, 0755); err != nil {
			LogError("åˆ›å»ºç›®å½•å¤±è´¥ %s: %v", targetDir, err)
			continue
		}

		// æ·»åŠ åˆ°ç¼“å­˜
		fp.dirCacheMutex.Lock()
		fp.dirCache[targetDir] = true
		fp.dirCacheMutex.Unlock()

		createdDirs = append(createdDirs, targetDir)
		LogInfo("âœ… é¢„åˆ›å»ºç›®å½•: %s", targetDir)
	}

	duration := time.Since(startTime)
	LogInfo("ğŸ‰ æ‰¹é‡é¢„åˆ›å»ºç›®å½•å®Œæˆ: åˆ›å»ºäº† %d ä¸ªç›®å½•ï¼Œè€—æ—¶ %v", len(createdDirs), duration)

	return nil
}

// AsyncCreateDirectory å¼‚æ­¥åˆ›å»ºç›®å½•
func (fp *FileProcessor) AsyncCreateDirectory(dirPath string) <-chan error {
	resultChan := make(chan error, 1)

	go func() {
		defer close(resultChan)

		// æ£€æŸ¥ç¼“å­˜
		fp.dirCacheMutex.RLock()
		if exists, found := fp.dirCache[dirPath]; found && exists {
			fp.dirCacheMutex.RUnlock()
			resultChan <- nil
			return
		}
		fp.dirCacheMutex.RUnlock()

		// å¼‚æ­¥åˆ›å»ºç›®å½•
		if err := os.MkdirAll(dirPath, 0755); err != nil {
			resultChan <- err
			return
		}

		// æ›´æ–°ç¼“å­˜
		fp.dirCacheMutex.Lock()
		fp.dirCache[dirPath] = true
		fp.dirCacheMutex.Unlock()

		resultChan <- nil
	}()

	return resultChan
}

// ç»Ÿè®¡ä¿¡æ¯ç›¸å…³æ–¹æ³•
func (fp *FileProcessor) incrementProcessedFiles() {
	fp.mutex.Lock()
	defer fp.mutex.Unlock()
	fp.stats.ProcessedFiles++
}

func (fp *FileProcessor) incrementMovedFiles() {
	fp.mutex.Lock()
	defer fp.mutex.Unlock()
	fp.stats.MovedFiles++
}

func (fp *FileProcessor) incrementDeletedFiles() {
	fp.mutex.Lock()
	defer fp.mutex.Unlock()
	fp.stats.DeletedFiles++
}

func (fp *FileProcessor) incrementErrorCount() {
	fp.mutex.Lock()
	defer fp.mutex.Unlock()
	fp.stats.ErrorCount++
}

func (fp *FileProcessor) addTotalSize(size int64) {
	fp.mutex.Lock()
	defer fp.mutex.Unlock()
	fp.stats.TotalSize += size
}

// GetStats è·å–å¤„ç†ç»Ÿè®¡ä¿¡æ¯
func (fp *FileProcessor) GetStats() ProcessorStats {
	fp.mutex.RLock()
	defer fp.mutex.RUnlock()
	return fp.stats
}

// printStats æ‰“å°ç»Ÿè®¡ä¿¡æ¯
func (fp *FileProcessor) printStats() {
	stats := fp.GetStats()

	// è®¡ç®—å¤„ç†æ—¶é—´
	duration := time.Since(stats.StartTime)

	// æ‰“å°åˆ†éš”çº¿
	fmt.Println(strings.Repeat("=", 60))
	fmt.Println("                    æ–‡ä»¶å¤„ç†ç»Ÿè®¡æŠ¥å‘Š")
	fmt.Println(strings.Repeat("=", 60))

	// åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
	fmt.Printf("ğŸ“Š å¤„ç†æ€»æ•°: %d ä¸ªæ–‡ä»¶\n", stats.ProcessedFiles)
	fmt.Printf("ğŸ“ ç§»åŠ¨æ–‡ä»¶: %d ä¸ª\n", stats.MovedFiles)
	fmt.Printf("ğŸ—‘ï¸  åˆ é™¤é‡å¤: %d ä¸ª\n", stats.DeletedFiles)
	fmt.Printf("âŒ å¤„ç†é”™è¯¯: %d ä¸ª\n", stats.ErrorCount)
	fmt.Printf("ğŸ’¾ æ€»å¤„ç†å¤§å°: %s\n", formatFileSize(stats.TotalSize))
	fmt.Printf("â±ï¸  å¤„ç†æ—¶é—´: %v\n", duration.Round(time.Second))

	// è®¡ç®—å¤„ç†é€Ÿåº¦
	if duration.Seconds() > 0 {
		filesPerSecond := float64(stats.ProcessedFiles) / duration.Seconds()
		bytesPerSecond := float64(stats.TotalSize) / duration.Seconds()
		fmt.Printf("ğŸš€ å¤„ç†é€Ÿåº¦: %.1f æ–‡ä»¶/ç§’, %s/ç§’\n", filesPerSecond, formatFileSize(int64(bytesPerSecond)))
	}

	// è®¡ç®—ç™¾åˆ†æ¯”
	if stats.ProcessedFiles > 0 {
		movePercent := float64(stats.MovedFiles) / float64(stats.ProcessedFiles) * 100
		deletePercent := float64(stats.DeletedFiles) / float64(stats.ProcessedFiles) * 100
		errorPercent := float64(stats.ErrorCount) / float64(stats.ProcessedFiles) * 100

		fmt.Println(strings.Repeat("-", 60))
		fmt.Printf("ğŸ“ˆ ç§»åŠ¨æ–‡ä»¶æ¯”ä¾‹: %.1f%%\n", movePercent)
		fmt.Printf("ğŸ“ˆ é‡å¤æ–‡ä»¶æ¯”ä¾‹: %.1f%%\n", deletePercent)
		fmt.Printf("ğŸ“ˆ é”™è¯¯ç‡: %.1f%%\n", errorPercent)
	}

	// å¹³å‡æ–‡ä»¶å¤§å°
	if stats.MovedFiles > 0 {
		avgSize := stats.TotalSize / stats.MovedFiles
		fmt.Printf("ğŸ“ å¹³å‡æ–‡ä»¶å¤§å°: %s\n", formatFileSize(avgSize))
	}

	fmt.Println(strings.Repeat("=", 60))

	// åŒæ—¶è¾“å‡ºåˆ°æ—¥å¿— - ä½¿ç”¨DEBUGçº§åˆ«è®°å½•è¯¦ç»†æ€§èƒ½ç»Ÿè®¡
	LogDebug("å¤„ç†ç»Ÿè®¡: æ€»è®¡=%d, ç§»åŠ¨=%d, åˆ é™¤=%d, é”™è¯¯=%d, æ€»å¤§å°=%s, è€—æ—¶=%v",
		stats.ProcessedFiles,
		stats.MovedFiles,
		stats.DeletedFiles,
		stats.ErrorCount,
		formatFileSize(stats.TotalSize),
		duration.Round(time.Second),
	)
}

// showProgress æ˜¾ç¤ºå®æ—¶å¤„ç†è¿›åº¦
func (fp *FileProcessor) showProgress(done <-chan bool) {
	ticker := time.NewTicker(2 * time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-done:
			// æ¸…é™¤è¿›åº¦æ˜¾ç¤º
			fmt.Printf("\r%s\r", strings.Repeat(" ", 80))
			return
		case <-ticker.C:
			stats := fp.GetStats()
			duration := time.Since(stats.StartTime)

			// è®¡ç®—å¤„ç†é€Ÿåº¦
			var speed string
			if duration.Seconds() > 0 {
				filesPerSecond := float64(stats.ProcessedFiles) / duration.Seconds()
				speed = fmt.Sprintf("%.1f æ–‡ä»¶/ç§’", filesPerSecond)
			} else {
				speed = "è®¡ç®—ä¸­..."
			}

			// æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯
			progressMsg := fmt.Sprintf("\râš¡ å¤„ç†ä¸­: %d ä¸ªæ–‡ä»¶ | ç§»åŠ¨: %d | åˆ é™¤: %d | é”™è¯¯: %d | é€Ÿåº¦: %s | è€—æ—¶: %v",
				stats.ProcessedFiles,
				stats.MovedFiles,
				stats.DeletedFiles,
				stats.ErrorCount,
				speed,
				duration.Round(time.Second),
			)

			// ç¡®ä¿ä¸è¶…è¿‡ç»ˆç«¯å®½åº¦
			if len(progressMsg) > 120 {
				progressMsg = progressMsg[:117] + "..."
			}

			fmt.Print(progressMsg)
		}
	}
}